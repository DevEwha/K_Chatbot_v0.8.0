"""
vLLM v1(0.15.1)ì„ ìœ„í•œ ì½”ë“œ 
* ëª¨ë“  Decoder-only ëª¨ë¸ ì§€ì›(Llama, Mistral, QWen, Phi, Gemma, GPT-2, Falconë“±)
ë ˆì´ì–´ í•­ìƒ ì‹¤í–‰í•´ topology ë¶ˆë³€
Path A(ë ˆì´ì–´ í†µê³¼)+Path B(ì§ì ‘ ì—°ê²°) ë‘˜ ë‹¤ ê³„ì‚°
Alphaë¡œ ì–´ëŠ ê²½ë¡œë¥¼ ë‹¤ìŒ ë ˆì´ì–´ë¡œ ì „ë‹¬í• ì§€ ì„ íƒ
"""


from typing import Optional, List, Dict, Any
import importlib
import threading
import inspect
import os
import torch
import torch.nn as nn
import sys

from vllm.config import VllmConfig
from vllm.model_executor.layers.vocab_parallel_embedding import VocabParallelEmbedding
from vllm.model_executor.layers.layernorm import RMSNorm



from safetensors.torch import load_file 

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from model_config import (
    get_model_type,
    get_layer_class_info,
    get_weight_pattern,
)

# Universal bypass layer
from universal_bypass_layer import UniversalBypassLayer 

class ProgressiveModelDualPath(nn.Module):
    """
    Universal Progressive Model with Dual-Path Design

    ì§€ì› ëª¨ë¸:
    - LLaMA (1, 2, 3)
    - Mistral
    - Qwen2
    - Gemma (1, 2)
    - Phi (2, 3)
    - GPT-2
    - Falcon
    - ê¸°íƒ€ Decoder-only ëª¨ë¸

    í•µì‹¬ ì•„ì´ë””ì–´:
    - ë ˆì´ì–´ëŠ” í•­ìƒ ì‹¤í–‰ (CUDA Graph topology ë¶ˆë³€)
    - ë‘ ê²½ë¡œë¥¼ ëª¨ë‘ ê³„ì‚°:
      * Path A: ë ˆì´ì–´ë¥¼ í†µê³¼í•œ ê°’
      * Path B: ë ˆì´ì–´ ê°„ ì§ì ‘ ì—°ê²° (bypass)
    - Alphaë¡œ ì–´ëŠ ê²½ë¡œë¥¼ ì‚¬ìš©í• ì§€ ì„ íƒ:
      * alpha=1: Path A (ë ˆì´ì–´ í†µê³¼)
      * alpha=0: Path B (ì§ì ‘ ì—°ê²°)
      * 0<alpha<1: blend

    CUDA Graph ì•ˆì „ì„±:
    - ë ˆì´ì–´ í•­ìƒ ì‹¤í–‰ â†’ kernel sequence ë¶ˆë³€
    - Path A/B ë‘˜ ë‹¤ í•­ìƒ ê³„ì‚° â†’ topology ë¶ˆë³€
    - Alpha blending í•­ìƒ ìˆ˜í–‰ â†’ topology ë¶ˆë³€
    - Alpha ê°’ë§Œ ë³€ê²½ (scalar buffer) â†’ CUDA Graph safe
    - NO .item() calls in forward â†’ capture safe!

    Partial KV Recomputation:
    - Stage ì „í™˜ ì‹œ boundary layer ê¸°ì¤€ KV cache ë¶€ë¶„ ì¬ê³„ì‚°
    - Boundary ì´ì „ layer: KV-only (norm + qkv_proj + rotary + cache write)
    - Boundary ì´í›„ layer: full forward
    - Prefill(eager mode)ì—ì„œë§Œ ë™ì‘ â†’ CUDA Graph ì¬ìº¡ì²˜ ì—†ìŒ
    """

    def __init__(
        self,
        vllm_config: VllmConfig,
        prefix: str = "",
        pruned_layer_indices: Optional[List[int]] = None,
    ):
        super().__init__()

        config = vllm_config.model_config.hf_config
        self.config = config
        self.vllm_config = vllm_config

        # Get normalized model type
        self.model_type = get_model_type(config)

        self.initially_inactive = set(pruned_layer_indices or [])

        # Embedding
        self.embed_tokens = VocabParallelEmbedding(
            config.vocab_size,
            config.hidden_size,
        )

        # Decoder layers
        self.layers = nn.ModuleList()
        self._init_layers(prefix)
        self._layer_forward_mode = self._resolve_layer_forward_mode()

        # Final norm
        self.norm = RMSNorm(
            config.hidden_size,
            eps=getattr(config, 'rms_norm_eps', 1e-6),
        )

        self.current_adapter = None

        # â”€â”€ Partial KV Recomputation â”€â”€
        # layer_idx â†’ {"output": (hidden_states_cpu, residual_cpu)}
        self._layer_output_cache: Dict[int, Any] = {}
        # Noneì´ë©´ ì¼ë°˜ forward, ì •ìˆ˜ë©´ í•´ë‹¹ layerë¶€í„° full forward
        self._partial_recompute_boundary: Optional[int] = None
        # ìºì‹±í•  ìµœëŒ€ ë ˆì´ì–´ ì¸ë±ìŠ¤ (ë‹¤ìŒ stageì˜ boundary-1)
        self._max_cacheable_layer: Optional[int] = None

        # â”€â”€ GPU-resident Partial Recompute (Method A) â”€â”€
        # CPU ë³µì‚¬ ì—†ì´ GPU persistent bufferì—ì„œ ì§ì ‘ boundary hidden states ì‚¬ìš©.
        # Front layers KV cacheëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€, back layersë§Œ ì¬ê³„ì‚°.
        self._recompute_from_boundary_gpu: Optional[int] = None

        # â”€â”€ Persistent GPU Buffers (CUDA graph safe) â”€â”€
        # index_copy_ëŠ” in-place ì—°ì‚° â†’ CUDA graphì— ìº¡ì²˜ë¨
        # Prefill (eager): ì§ì ‘ ì‹¤í–‰, Decode (graph replay): ìë™ ì‹¤í–‰
        # ë”°ë¼ì„œ prefill + decode ëª¨ë‘ì—ì„œ hidden statesê°€ ìë™ ëˆ„ì ë¨
        self._persistent_h_buffers: List[torch.Tensor] = []
        self._persistent_r_buffers: List[torch.Tensor] = []
        self._persistent_buffers_initialized = False

        print(f"âœ… Initialized ProgressiveModelDualPath for: {self.model_type}")
        print(f"âœ… Layer forward mode: {self._layer_forward_mode}")
    
    def _get_layer_class(self, model_type: str):
        """
        ëª¨ë¸ íƒ€ì…ì— ë”°ë¥¸ ë ˆì´ì–´ í´ë˜ìŠ¤ ë™ì  ë¡œë“œ
        
        Args:
            model_type: Normalized model type (e.g., "llama", "mistral")
            
        Returns:
            Layer class (e.g., LlamaDecoderLayer)
        """
        layer_info = get_layer_class_info(model_type)
        
        # Try v1 module first
        try:
            module = importlib.import_module(layer_info["v1_module"])
            layer_class = getattr(module, layer_info["layer_class"])
            print(f"  âœ… Loaded {layer_info['layer_class']} from v1 module")
            return layer_class
        except (ImportError, AttributeError):
            pass
        
        # Fallback to v0 module
        try:
            module = importlib.import_module(layer_info["module"])
            layer_class = getattr(module, layer_info["layer_class"])
            print(f"  âœ… Loaded {layer_info['layer_class']} from v0 module")
            return layer_class
        except (ImportError, AttributeError) as e:
            raise ImportError(
                f"Failed to load layer class for model type '{model_type}'. "
                f"Tried: {layer_info['v1_module']}.{layer_info['layer_class']}, "
                f"{layer_info['module']}.{layer_info['layer_class']}. "
                f"Error: {e}"
            )
    
    def _init_layers(self, prefix: str):
        """ëª¨ë“  ë ˆì´ì–´ë¥¼ UniversalBypassLayerë¡œ ê°ì‹¸ê¸°"""
        
        # Get layer class for this model type
        LayerClass = self._get_layer_class(self.model_type)
        
        num_layers = self.config.num_hidden_layers
        
        for layer_idx in range(num_layers):
            # Base layer ìƒì„± - Try multiple initialization styles
            base_layer = self._create_base_layer(LayerClass, layer_idx, prefix)
            
            # UniversalBypassLayerë¡œ ê°ì‹¸ê¸°
            if layer_idx in self.initially_inactive:
                print(f"[Init] Layer {layer_idx:2d}: DualPath (alpha=0, Path B)")
                
                # Weightë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”
                # alpha=0ì¼ ë•Œ Path AëŠ” zero-outputì´ë¯€ë¡œ GPU ìµœì í™”ë¨
                self._initialize_weights_to_zero(base_layer)
                
                wrapped = UniversalBypassLayer(
                    base_layer=base_layer,
                    initial_alpha=0.0,
                    layer_idx=layer_idx,
                )
                self.layers.append(wrapped)
            else:
                print(f"[Init] Layer {layer_idx:2d}: DualPath (alpha=1, Path A)")
                
                wrapped = UniversalBypassLayer(
                    base_layer=base_layer,
                    initial_alpha=1.0,
                    layer_idx=layer_idx,
                )
                self.layers.append(wrapped)
    
    def _create_base_layer(self, LayerClass, layer_idx: int, prefix: str):
        """
        ë²”ìš©ì ì¸ ë ˆì´ì–´ ì´ˆê¸°í™”
        
        ë‹¤ì–‘í•œ ì´ˆê¸°í™” ì‹œê·¸ë‹ˆì²˜ë¥¼ ì‹œë„í•©ë‹ˆë‹¤:
        1. v1 style: vllm_config only
        2. v0 style: config + cache_config + quant_config
        3. Minimal: layer_idx + config
        """
        layer_prefix = f"{prefix}.layers.{layer_idx}"
        
        # Try v1 style first (vllm_configë§Œ ì‚¬ìš©)
        try:
            return LayerClass(
                vllm_config=self.vllm_config,
                prefix=layer_prefix,
            )
        except TypeError:
            pass
        
        # Try v0 style with full config
        try:
            return LayerClass(
                config=self.config,
                cache_config=self.vllm_config.cache_config,
                quant_config=self.vllm_config.quant_config,
                prefix=layer_prefix,
            )
        except TypeError:
            pass
        
        # Try with layer_idx
        try:
            return LayerClass(
                layer_idx=layer_idx,
                config=self.config,
                prefix=layer_prefix,
            )
        except TypeError:
            pass
        
        # Minimal fallback
        try:
            return LayerClass(
                config=self.config,
                prefix=layer_prefix,
            )
        except TypeError as e:
            raise TypeError(
                f"Failed to initialize {LayerClass.__name__} with any known signature. "
                f"Last error: {e}"
            )
    
    def _initialize_weights_to_zero(self, layer: nn.Module):
        """Weightë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”"""
        for param in layer.parameters():
            param.data.zero_()

    def _resolve_layer_forward_mode(self) -> str:
        """
        ëŸ°íƒ€ì„ try/except ë””ìŠ¤íŒ¨ì¹˜ë¥¼ ì—†ì• ê¸° ìœ„í•´, ì´ˆê¸°í™” ì‹œ 1íšŒë§Œ
        layer forward ì‹œê·¸ë‹ˆì²˜ë¥¼ ë¶„ì„í•´ ê³ ì • ëª¨ë“œë¥¼ ì„ íƒí•œë‹¤.
        """
        if len(self.layers) == 0:
            return "kwargs_v1"

        layer = self.layers[0].layer
        try:
            sig = inspect.signature(layer.forward)
            param_names = {
                p.name for p in sig.parameters.values()
                if p.kind in (
                    inspect.Parameter.POSITIONAL_OR_KEYWORD,
                    inspect.Parameter.KEYWORD_ONLY,
                )
            }
        except (TypeError, ValueError):
            param_names = set()

        if {"positions", "hidden_states", "residual"}.issubset(param_names):
            return "kwargs_v1"
        if {"positions", "hidden_states"}.issubset(param_names):
            return "kwargs_no_residual"
        return "positional"
    
    # ================================================================
    # Persistent GPU Buffers (CUDA graph safe caching)
    # ================================================================

    def _init_persistent_buffers(self, device, dtype):
        """
        Persistent GPU buffer ì‚¬ì „ í• ë‹¹ (ìµœì´ˆ forward ì‹œ 1íšŒ í˜¸ì¶œ)

        CUDA graph ìº¡ì²˜ ì „ì— í˜¸ì¶œë˜ì–´ì•¼ í•¨ (memory profiling ë‹¨ê³„ì—ì„œ ìë™ í˜¸ì¶œ)
        - index_copy_()ê°€ CUDA graphì— ìº¡ì²˜ë˜ë ¤ë©´ bufferê°€ ë¨¼ì € ì¡´ì¬í•´ì•¼ í•¨
        - vLLM flow: model init â†’ weight load â†’ memory profile(forward) â†’ graph capture(forward)
        - memory profile ì‹œ ìµœì´ˆ forward â†’ ì—¬ê¸°ì„œ buffer í• ë‹¹
        """
        if self._persistent_buffers_initialized:
            return

        max_seq_len = self.vllm_config.model_config.max_model_len
        hidden_dim = self.config.hidden_size
        num_layers = len(self.layers)

        for _ in range(num_layers):
            self._persistent_h_buffers.append(
                torch.zeros(max_seq_len, hidden_dim, dtype=dtype, device=device)
            )
            self._persistent_r_buffers.append(
                torch.zeros(max_seq_len, hidden_dim, dtype=dtype, device=device)
            )

        self._persistent_buffers_initialized = True
        mem_mb = num_layers * max_seq_len * hidden_dim * 2 * 2 / (1024**2)
        print(f"âœ… Persistent GPU buffers: {num_layers} layers Ã— {max_seq_len} seq = {mem_mb:.0f} MB")

    def sync_persistent_cache(self, seq_len: int):
        """
        GPU persistent buffer â†’ CPU _layer_output_cache

        Stage ì „í™˜ ì§ì „ì— chatbotì—ì„œ í˜¸ì¶œ.
        GPU bufferì˜ [0:seq_len] êµ¬ê°„ì„ CPUë¡œ ë³µì‚¬í•˜ì—¬ partial recomputeì— ì‚¬ìš©.
        """
        if not self._persistent_buffers_initialized:
            print(f"[Cache] âš ï¸ Persistent buffers not initialized")
            return

        max_layer = self._max_cacheable_layer if self._max_cacheable_layer is not None else len(self.layers) - 1

        self._layer_output_cache.clear()
        for layer_idx in range(max_layer + 1):
            h = self._persistent_h_buffers[layer_idx][:seq_len].cpu()
            r = self._persistent_r_buffers[layer_idx][:seq_len].cpu()
            self._layer_output_cache[layer_idx] = {"output": (h, r)}

        print(f"[Cache] Synced {max_layer + 1} layers Ã— {seq_len} tokens (GPU â†’ CPU)")

    def clear_persistent_buffers(self):
        """Persistent buffer ì´ˆê¸°í™” (warmup ë°ì´í„° ì œê±°)"""
        with torch.inference_mode():
            for buf in self._persistent_h_buffers:
                buf.zero_()
            for buf in self._persistent_r_buffers:
                buf.zero_()

    # ================================================================
    # Forward: Dual-Path Design (Universal for all decoder models)
    # ================================================================

    def forward(
        self,
        input_ids: torch.Tensor,
        positions: torch.Tensor,
        intermediate_tensors: Optional[Any] = None,
        inputs_embeds: Optional[torch.Tensor] = None,
    ) -> torch.Tensor:
        """
        Forward with Dual-Path Design (Universal)

        í•µì‹¬:
        1. ë ˆì´ì–´ í•­ìƒ ì‹¤í–‰ (topology ë¶ˆë³€)
        2. Path A/B ë‘˜ ë‹¤ ê³„ì‚°
        3. Alphaë¡œ ì„ íƒ

        Partial KV Recomputation:
        - _partial_recompute_boundaryê°€ ì„¤ì •ë˜ë©´, boundary ì´ì „ ë ˆì´ì–´ëŠ”
          KV-only forward (norm+qkv+rotary+cache_writeë§Œ), boundary ì´í›„ëŠ” full forward
        - ìºì‹œëœ hidden statesë¥¼ ì‚¬ìš©í•´ boundary ì´ì „ ë ˆì´ì–´ë¥¼ ë¹ ë¥´ê²Œ ì²˜ë¦¬
        - Prefill(eager mode)ì—ì„œë§Œ ë™ì‘ â†’ CUDA Graph ì¬ìº¡ì²˜ ì—†ìŒ

        CUDA Graph Safety:
        - get_alpha() returns tensor (not float!)
        - No .item() calls anywhere in forward
        - All operations on GPU tensors
        """

        # Embedding
        if inputs_embeds is not None:
            hidden_states = inputs_embeds
        else:
            hidden_states = self.embed_tokens(input_ids)

        residual = None

        # â”€â”€ GPU-resident Partial Recompute (Method A) â”€â”€
        # Front layers KV cacheëŠ” ê°€ì¤‘ì¹˜ ë³€ê²½ ì—†ìŒ â†’ ê·¸ëŒ€ë¡œ ìœ íš¨.
        # _persistent_h_buffers[gpu_boundary-1]ì—ì„œ boundary hidden states ì§ì ‘ ì½ì–´
        # back layersë§Œ ì¬ê³„ì‚°. CPU ë³µì‚¬, KV-only pass ì™„ì „ ì œê±°.
        gpu_boundary = self._recompute_from_boundary_gpu
        if gpu_boundary is not None:
            seq_len = hidden_states.shape[0]
            if seq_len > 1 and self._persistent_buffers_initialized:
                # boundary-1 ë ˆì´ì–´ì˜ GPU ì €ì¥ hidden states ì½ê¸°
                # positions: [seq_len] í…ì„œ, buffer[positions] â†’ [seq_len, hidden]
                boundary_h = self._persistent_h_buffers[gpu_boundary - 1][positions]
                boundary_r = self._persistent_r_buffers[gpu_boundary - 1][positions]

                self._recompute_from_boundary_gpu = None  # 1íšŒì„±

                print(f"\n[GPURecompute] ğŸš€ GPU-resident partial recompute")
                print(f"  Boundary layer : {gpu_boundary}")
                print(f"  Front layers   : 0-{gpu_boundary-1} â†’ skipped (KV cache already valid)")
                print(f"  Back layers    : {gpu_boundary}-{len(self.layers)-1} â†’ full forward")
                print(f"  Tokens         : {seq_len}")

                # Front layers ì™„ì „ ìŠ¤í‚µ: í•´ë‹¹ attentionì˜ write_kv_to_cache í˜¸ì¶œ ì•ˆ ë¨
                # â†’ front layer KV cache slots ê·¸ëŒ€ë¡œ ìœ ì§€
                hidden_states = boundary_h
                residual = boundary_r

                # Back layersë§Œ ì‹¤í–‰ (dual-path ê·¸ëŒ€ë¡œ ìœ ì§€)
                for layer_idx in range(gpu_boundary, len(self.layers)):
                    layer_wrapper = self.layers[layer_idx]

                    alpha = layer_wrapper.get_alpha()  # tensor, CUDA Graph safe

                    # Path A: Layer í†µê³¼ (attentionì´ ë‚´ë¶€ì ìœ¼ë¡œ write_kv_to_cache í˜¸ì¶œ)
                    hidden_a, residual_a = self._call_layer_forward_fast(
                        layer_wrapper.layer,
                        positions=positions,
                        hidden_states=hidden_states,
                        residual=residual,
                    )

                    # Path B: bypass
                    hidden_b = hidden_states
                    residual_b = residual

                    # Alpha blending
                    hidden_states = alpha * hidden_a + (1.0 - alpha) * hidden_b
                    if residual_a is not None and residual_b is not None:
                        residual = alpha * residual_a + (1.0 - alpha) * residual_b
                    elif residual_a is not None:
                        residual = alpha * residual_a
                    else:
                        residual = residual_b

                    # Persistent buffer ì—…ë°ì´íŠ¸ (back layersìš©)
                    if self._max_cacheable_layer is None or layer_idx <= self._max_cacheable_layer:
                        self._persistent_h_buffers[layer_idx].index_copy_(
                            0, positions, hidden_states)
                        if residual is not None:
                            self._persistent_r_buffers[layer_idx].index_copy_(
                                0, positions, residual)

                    if layer_idx == gpu_boundary or layer_idx == len(self.layers) - 1:
                        print(f"  Layer {layer_idx:2d}: â†» full forward (GPU-resident recompute)")

                print(f"[GPURecompute] âœ… Back layers recomputed, front KV cache preserved\n")

                # Final residual + norm
                if residual is not None:
                    hidden_states = hidden_states + residual
                hidden_states = self.norm(hidden_states)
                return hidden_states

            else:
                # seq_len=1 (decode phase) ì´ê±°ë‚˜ ë²„í¼ ë¯¸ì´ˆê¸°í™” â†’ ëª¨ë“œ í´ë¦¬ì–´ í›„ ì¼ë°˜ forward
                self._recompute_from_boundary_gpu = None

        # â”€â”€ Partial KV Recompute Mode â”€â”€
        boundary = self._partial_recompute_boundary
        use_partial = (
            boundary is not None
            and len(self._layer_output_cache) > 0
            and self._is_cache_compatible(hidden_states)
        )

        # ë””ë²„ê·¸: Partial recompute ì‹œì‘
        if use_partial:
            print(f"\n[PartialRecompute] ğŸš€ Starting partial KV recomputation")
            print(f"  Boundary: {boundary}")
            print(f"  Cached layers: {len(self._layer_output_cache)}")
            kv_only_count = 0
            full_forward_count = 0

        for layer_idx, layer_wrapper in enumerate(self.layers):

            if use_partial and layer_idx < boundary:
                # â”€â”€ KV-only path: ìºì‹œëœ hidden statesë¡œ KVë§Œ ê¸°ë¡ â”€â”€

                # ì…ë ¥ ê²°ì •: Layer 0ì€ í˜„ì¬ embedding, ë‚˜ë¨¸ì§€ëŠ” ì´ì „ ë ˆì´ì–´ ì¶œë ¥
                if layer_idx == 0:
                    kv_input_h = hidden_states
                    kv_input_r = residual
                else:
                    prev_cached = self._layer_output_cache.get(layer_idx - 1)
                    if prev_cached is not None:
                        kv_input_h = prev_cached["output"][0].to(hidden_states.device)
                        kv_input_r = prev_cached["output"][1].to(hidden_states.device) if prev_cached["output"][1] is not None else None
                    else:
                        # Fallback: í˜„ì¬ hidden states ì‚¬ìš©
                        kv_input_h = hidden_states
                        kv_input_r = residual

                # KV-only: norm â†’ qkv_proj â†’ rotary â†’ cache_write
                self._kv_only_forward_layer(
                    layer_wrapper.layer,
                    positions=positions,
                    hidden_states=kv_input_h,
                    residual=kv_input_r,
                )

                # ì¶œë ¥: í˜„ì¬ ë ˆì´ì–´ ìºì‹œì—ì„œ
                cached = self._layer_output_cache.get(layer_idx)
                if cached is not None:
                    hidden_states = cached["output"][0].to(hidden_states.device)
                    residual = cached["output"][1].to(hidden_states.device) if cached["output"][1] is not None else None

                    # ë””ë²„ê·¸: KV-only ì¹´ìš´íŠ¸
                    if layer_idx == 0 or layer_idx % 5 == 0 or layer_idx == boundary - 1:
                        print(f"  Layer {layer_idx:2d}: âœ“ KV-only (cached)")
                    kv_only_count += 1
                    continue

            # â”€â”€ Normal dual-path forward â”€â”€
            # Alpha ê°’ (tensor, CUDA Graph safe!)
            alpha = layer_wrapper.get_alpha()  # â† Returns tensor!

            # Path A: Layer í†µê³¼
            hidden_a, residual_a = self._call_layer_forward_fast(
                layer_wrapper.layer,
                positions=positions,
                hidden_states=hidden_states,
                residual=residual,
            )

            # Path B: ë ˆì´ì–´ ê°„ ì§ì ‘ ì—°ê²° (bypass)
            hidden_b = hidden_states  # ì´ì „ ê°’ ê·¸ëŒ€ë¡œ
            residual_b = residual if residual is not None else None

            # Alphaë¡œ ê²½ë¡œ ì„ íƒ
            # Hidden states blending (tensor operations, CUDA Graph safe!)
            hidden_states = alpha * hidden_a + (1.0 - alpha) * hidden_b

            # Residual blending
            if residual_a is not None and residual_b is not None:
                residual = alpha * residual_a + (1.0 - alpha) * residual_b
            elif residual_a is not None:
                residual = alpha * residual_a
            else:
                residual = residual_b

            # â”€â”€ Persistent GPU bufferì— hidden states ê¸°ë¡ â”€â”€
            # index_copy_()ëŠ” in-place ì—°ì‚° â†’ CUDA graphì— ìº¡ì²˜ë¨
            # Prefill(eager): ì§ì ‘ ì‹¤í–‰, Decode(graph replay): ìë™ ì‹¤í–‰
            if self._max_cacheable_layer is None or layer_idx <= self._max_cacheable_layer:
                self._init_persistent_buffers(hidden_states.device, hidden_states.dtype)
                self._persistent_h_buffers[layer_idx].index_copy_(0, positions, hidden_states)
                if residual is not None:
                    self._persistent_r_buffers[layer_idx].index_copy_(0, positions, residual)

            # ë””ë²„ê·¸: Full forward ì¹´ìš´íŠ¸
            if use_partial and layer_idx >= boundary:
                if layer_idx == boundary or layer_idx % 5 == 0 or layer_idx == len(self.layers) - 1:
                    print(f"  Layer {layer_idx:2d}: â†» Full forward (recompute)")
                full_forward_count += 1

        # ë””ë²„ê·¸: Partial recompute ì™„ë£Œ í†µê³„
        if use_partial:
            print(f"\n[PartialRecompute] âœ… Completed")
            print(f"  KV-only:      {kv_only_count} layers (skipped attention+MLP)")
            print(f"  Full forward: {full_forward_count} layers (recomputed)")
            savings = (kv_only_count / len(self.layers)) * 100
            print(f"  Savings:      ~{savings:.1f}% of layers optimized\n")

        # Partial recomputeëŠ” 1íšŒì„± (ì„±ê³µ ì—¬ë¶€ ë¬´ê´€, ë‹¤ìŒ forwardë¶€í„° ì¼ë°˜ ëª¨ë“œ)
        if boundary is not None:
            self._partial_recompute_boundary = None

        # Final residual add
        if residual is not None:
            hidden_states = hidden_states + residual

        # Final norm
        hidden_states = self.norm(hidden_states)

        return hidden_states

    # ================================================================
    # Partial KV Recomputation Helpers
    # ================================================================

    def _is_cache_compatible(self, current_hidden: torch.Tensor) -> bool:
        """
        ìºì‹œëœ hidden statesê°€ í˜„ì¬ ì…ë ¥ê³¼ í˜¸í™˜ë˜ëŠ”ì§€ í™•ì¸

        Causal attention + ë™ì¼ ê°€ì¤‘ì¹˜ â†’ ë™ì¼ ì…ë ¥ì´ë©´ ë™ì¼ hidden states
        ë”°ë¼ì„œ ê¸¸ì´ ì¼ì¹˜ë§Œ í™•ì¸í•˜ë©´ ì¶©ë¶„ (ê°’ ë¹„êµ ë¶ˆí•„ìš”, CPU-GPU ì „ì†¡ íšŒí”¼)
        """
        current_len = current_hidden.shape[0]

        # ğŸ”¥ Decode phase (seq_len=1)ëŠ” partial recompute ë¶ˆí•„ìš” â†’ ì¦‰ì‹œ False
        if current_len == 1:
            return False

        if 0 not in self._layer_output_cache:
            print(f"[CacheCheck] âŒ No cached layer 0")
            return False

        cached_len = self._layer_output_cache[0]["output"][0].shape[0]

        compatible = (cached_len == current_len)
        print(f"[CacheCheck] Cached: {cached_len} tokens, Current: {current_len} tokens â†’ "
              f"{'âœ… Compatible' if compatible else 'âŒ Incompatible'}")
        return compatible

    def _kv_only_forward_layer(
        self,
        layer: nn.Module,
        positions: torch.Tensor,
        hidden_states: torch.Tensor,
        residual: Optional[torch.Tensor],
    ) -> None:
        """
        KV-only forward: norm â†’ qkv_proj â†’ rotary â†’ write_kv_to_cache
        Attention ì—°ì‚°(softmax + o_proj) ë° MLP ì‹¤í–‰ ì•ˆ í•¨.

        ì§€ì›: Llama/Mistral (self_attn + input_layernorm),
              Falcon (self_attention + ln_attn + query_key_value)
        """
        # Falcon ê°ì§€: self_attention + ln_attn ì¡°í•©
        is_falcon = hasattr(layer, 'self_attention') and hasattr(layer, 'ln_attn')

        # 1. Input layernorm
        if is_falcon:
            # Falcon: parallel attn/mlp êµ¬ì¡°, ln_attnë§Œ attention pathì— ì ìš©
            normed = layer.ln_attn(hidden_states)
        elif hasattr(layer, 'input_layernorm'):
            # Llama/Mistral: fused RMSNorm (hidden_states, residual) or plain call
            if residual is None:
                normed = layer.input_layernorm(hidden_states)
            else:
                try:
                    normed, _ = layer.input_layernorm(hidden_states, residual)
                except TypeError:
                    normed = layer.input_layernorm(hidden_states)
        else:
            normed = hidden_states

        # 2. Attention ëª¨ë“ˆ ì„ íƒ
        if is_falcon:
            attn = layer.self_attention
        else:
            attn = getattr(layer, 'self_attn', None)
        if attn is None:
            return

        # 3. QKV projection
        if is_falcon:
            qkv_proj = getattr(attn, 'query_key_value', None)
        else:
            qkv_proj = getattr(attn, 'qkv_proj', None)
        if qkv_proj is None:
            return

        qkv, _ = qkv_proj(normed)

        # Split Q, K, V
        q_size = getattr(attn, 'q_size', None)
        kv_size = getattr(attn, 'kv_size', None)
        if q_size is None or kv_size is None:
            return

        q, k, v = qkv.split([q_size, kv_size, kv_size], dim=-1)

        # Rotary embedding
        rotary_emb = getattr(attn, 'rotary_emb', None)
        if rotary_emb is not None:
            q, k = rotary_emb(positions, q, k)

        # Write to KV cache (skip attention computation)
        attn_module = getattr(attn, 'attn', None)
        if attn_module is not None and hasattr(attn_module, 'write_kv_to_cache'):
            attn_module.write_kv_to_cache(k, v)

    def set_partial_recompute(self, boundary_layer_idx: int) -> None:
        """
        Stage ì „í™˜ í›„ partial KV recomputation ëª¨ë“œ ì„¤ì •.
        boundary_layer_idx ì´ì „ layerëŠ” KV-only, ì´í›„ëŠ” full forward.
        """
        if boundary_layer_idx <= 0 or boundary_layer_idx >= len(self.layers):
            print(f"[PartialRecompute] Invalid boundary {boundary_layer_idx}, "
                  f"falling back to full recompute")
            self._partial_recompute_boundary = None
            return

        if len(self._layer_output_cache) == 0:
            print(f"[PartialRecompute] No cached hidden states, "
                  f"falling back to full recompute")
            self._partial_recompute_boundary = None
            return

        self._partial_recompute_boundary = boundary_layer_idx
        print(f"[PartialRecompute] Boundary set at layer {boundary_layer_idx}")
        print(f"  Layers 0-{boundary_layer_idx-1}: KV-only (cached hidden states)")
        print(f"  Layers {boundary_layer_idx}-{len(self.layers)-1}: full forward")

    def set_recompute_from_boundary_gpu(self, boundary_layer_idx: int) -> bool:
        """
        GPU-resident partial recompute ëª¨ë“œ ì„¤ì • (Method A).

        Stage ì „í™˜ í›„ í˜¸ì¶œ. Front layers KV cacheëŠ” ê°€ì¤‘ì¹˜ ë³€ê²½ ì—†ìœ¼ë¯€ë¡œ ìœ íš¨.
        _persistent_h_buffers[boundary-1]ì—ì„œ boundary hidden statesë¥¼ ì§ì ‘ ì½ì–´
        back layersë§Œ ì¬ê³„ì‚°. CPU ë³µì‚¬ ì—†ìŒ, KV-only pass ì—†ìŒ.

        Returns:
            True: ëª¨ë“œ ì„¤ì • ì„±ê³µ
            False: ë²„í¼ ë¯¸ì´ˆê¸°í™” ë“±ìœ¼ë¡œ ì„¤ì • ë¶ˆê°€ (ì¼ë°˜ forwardë¡œ ì§„í–‰ë¨)
        """
        if boundary_layer_idx <= 0 or boundary_layer_idx >= len(self.layers):
            print(f"[GPURecompute] Invalid boundary {boundary_layer_idx} "
                  f"(layers: {len(self.layers)}), GPU mode not set")
            return False

        if not self._persistent_buffers_initialized:
            print(f"[GPURecompute] Persistent buffers not initialized yet, "
                  f"GPU mode not available")
            return False

        self._recompute_from_boundary_gpu = boundary_layer_idx
        print(f"[GPURecompute] âœ… GPU-resident mode set: boundary={boundary_layer_idx}")
        print(f"  Front layers 0-{boundary_layer_idx-1}: skipped (KV cache already valid)")
        print(f"  Back layers {boundary_layer_idx}-{len(self.layers)-1}: full forward")
        return True

    def clear_hidden_cache(self) -> None:
        """Hidden state ìºì‹œ ì´ˆê¸°í™”"""
        self._layer_output_cache.clear()
        self._partial_recompute_boundary = None
        self._recompute_from_boundary_gpu = None
    
    def _call_layer_forward_fast(
        self,
        layer,
        positions,
        hidden_states,
        residual,
    ):
        """
        ì´ˆê¸°í™” ì‹œ ì„ íƒëœ ê³ ì • ëª¨ë“œë¡œ ë ˆì´ì–´ forwardë¥¼ í˜¸ì¶œ.
        (per-token try/except ë””ìŠ¤íŒ¨ì¹˜ ì œê±°)
        """
        mode = self._layer_forward_mode

        if mode == "kwargs_v1":
            output = layer(
                positions=positions,
                hidden_states=hidden_states,
                residual=residual,
            )
        elif mode == "kwargs_no_residual":
            output = layer(
                positions=positions,
                hidden_states=hidden_states,
            )
        else:
            output = layer(positions, hidden_states, residual)

        if isinstance(output, tuple):
            return output
        return output, None
    
    # ================================================================
    # Layer Activation (Weight Loading) - Universal
    # ================================================================
    
    def activate_layers(
        self,
        layer_indices: List[int],
        checkpoint_path: str,
    ) -> None:
        """
        ë ˆì´ì–´ í™œì„±í™”: alpha 0â†’1 + weight ë¡œë“œ (ë²”ìš©)
        
        CUDA Graph í˜¸í™˜:
        - .copy_()ë¡œ in-place weight ë¡œë“œ
        - alpha.fill_()ë¡œ in-place alpha ì—…ë°ì´íŠ¸
        - Topology ë¶ˆë³€ (ë ˆì´ì–´ëŠ” ê³„ì† ì‹¤í–‰ë¨)
        """
        print(f"\n{'='*60}")
        print(f"ACTIVATING LAYERS: {layer_indices}")
        print(f"Model Type: {self.model_type}")
        print(f"{'='*60}")
        
        # Checkpoint ë¡œë“œ
        print(f"Loading checkpoint from: {checkpoint_path}")
        state_dict = load_file(checkpoint_path)
        
        device = next(self.parameters()).device
        
        # Get weight naming pattern for this model
        weight_pattern = get_weight_pattern(self.model_type)
        
        for layer_idx in layer_indices:
            print(f"\nğŸ“‚ Activating layer {layer_idx}...")
            
            layer_wrapper = self.layers[layer_idx]
            
            # ì´ë¯¸ í™œì„±í™”ëœ ë ˆì´ì–´
            if layer_wrapper.is_active():
                print(f"  â„¹ï¸  Layer {layer_idx} is already active")
                continue
            
            # 1. Weight ì¶”ì¶œ
            print(f"  ğŸ”¥ Loading weights...")
            layer_prefix = f"model.layers.{layer_idx}."
            layer_weights = {
                k.replace(layer_prefix, ""): v
                for k, v in state_dict.items()
                if k.startswith(layer_prefix)
            }
            
            if not layer_weights:
                print(f"  âš ï¸  No weights found for layer {layer_idx}")
                continue
            
            # 2. In-place weight ë¡œë“œ (ë²”ìš©, CUDA Graph í˜¸í™˜!)
            loaded_count = self._load_layer_weights(
                layer_wrapper.layer,
                layer_weights,
                weight_pattern,
                device,
            )
            
            print(f"  âœ… Loaded {loaded_count} weight tensors")
            
            # 3. Alpha í™œì„±í™” (0 â†’ 1)
            layer_wrapper.activate()
            
            # 4. initially_inactiveì—ì„œ ì œê±°
            self.initially_inactive.discard(layer_idx)
            
            print(f"  âœ… Layer {layer_idx} activated!")
        
        print(f"\n{'='*60}")
        print(f"LAYER ACTIVATION COMPLETE")
        print(f"Inactive layers: {self.count_inactive_layers()}")
        print(f"â„¹ï¸  TopologyëŠ” ê³ ì •ë˜ì§€ë§Œ, vLLM ëŸ°íƒ€ì„ì—ì„œ graph ì¬ìº¡ì²˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ")
        print(f"{'='*60}\n")
    
    def prefetch_weights(self, checkpoint_path: str, layer_indices: List[int]) -> None:
        """
        ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ checkpointë¥¼ CPU ë©”ëª¨ë¦¬ì— ë¯¸ë¦¬ ë¡œë“œ.
        ì„œë¹™ ì¤‘ ë””ìŠ¤í¬ I/Oë¥¼ ë¯¸ë¦¬ ì²˜ë¦¬ â†’ ì „í™˜ ì‹œ GPU copyë§Œ ë‚¨ìŒ.

        ì•ˆì „ì¥ì¹˜:
        - ì´ë¯¸ ë™ì¼ indicesë¡œ ì™„ë£Œëœ prefetchëŠ” skip
        - ì§„í–‰ ì¤‘ì¸ prefetchê°€ ìˆìœ¼ë©´ ì™„ë£Œ ëŒ€ê¸° í›„ ìƒˆë¡œ ì‹œì‘
        - worker ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ eventëŠ” ë°˜ë“œì‹œ set (blocking ë°©ì§€)
        """
        # ì´ë¯¸ ë™ì¼ indicesë¡œ ì™„ë£Œëœ ê²½ìš° skip
        if (hasattr(self, '_prefetch_event')
                and self._prefetch_event.is_set()
                and hasattr(self, '_prefetch_indices')
                and self._prefetch_indices == list(layer_indices)):
            print("[Prefetch] Already completed for these layers, skipping")
            return

        # ì§„í–‰ ì¤‘ì¸ prefetchê°€ ìˆìœ¼ë©´ ì™„ë£Œ ëŒ€ê¸°
        if hasattr(self, '_prefetch_event') and not self._prefetch_event.is_set():
            print("[Prefetch] Waiting for previous prefetch to finish...")
            self._prefetch_event.wait()

        self._prefetch_buffer = None
        self._prefetch_indices = list(layer_indices)
        self._prefetch_path = checkpoint_path
        self._prefetch_event = threading.Event()

        def _worker():
            try:
                print(f"[Prefetch] Loading {checkpoint_path} in background...")
                state_dict = load_file(checkpoint_path)
                state_dict = {k: v.pin_memory() for k, v in state_dict.items()}
                self._prefetch_buffer = state_dict
                print(f"[Prefetch] âœ… {len(state_dict)} tensors ready in CPU pinned memory")
            except Exception as e:
                print(f"[Prefetch] âŒ Failed: {e}")
                self._prefetch_buffer = None
            finally:
                self._prefetch_event.set()  # ì˜ˆì™¸ê°€ ë‚˜ë„ ë°˜ë“œì‹œ set

        thread = threading.Thread(target=_worker, daemon=True)
        thread.start()

    def activate_layers_instant(
        self,
        layer_indices: List[int],
        wait_if_needed: bool = True,
    ) -> bool:
        """
        prefetch_weights()ë¡œ CPUì— ì˜¬ë ¤ë‘” ë²„í¼ì—ì„œ ì¦‰ê° í™œì„±í™”.
        ë””ìŠ¤í¬ I/O ì—†ì´ GPU copy + alpha ë³€ê²½ë§Œ ì‹¤í–‰.

        Returns:
            True: ì„±ê³µ
            False: prefetch ë¯¸ì™„ë£Œ (wait_if_needed=False)
        """
        if not hasattr(self, '_prefetch_event'):
            raise RuntimeError("prefetch_weights()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")

        if not self._prefetch_event.is_set():
            if wait_if_needed:
                print("[Prefetch] Waiting for background load to finish...")
                self._prefetch_event.wait()
            else:
                print("[Prefetch] Not ready yet.")
                return False

        if self._prefetch_buffer is None:
            raise RuntimeError("[Prefetch] ë²„í¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. prefetchê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        # indices ê²€ì¦
        if set(layer_indices) != set(self._prefetch_indices):
            raise ValueError(
                f"Layer indices mismatch: prefetch={self._prefetch_indices}, "
                f"requested={layer_indices}"
            )

        state_dict = self._prefetch_buffer
        device = next(self.parameters()).device
        weight_pattern = get_weight_pattern(self.model_type)

        print(f"\n{'='*60}")
        print(f"INSTANT ACTIVATION: {layer_indices}")
        print(f"{'='*60}")

        try:
            for layer_idx in layer_indices:
                layer_wrapper = self.layers[layer_idx]

                if layer_wrapper.is_active():
                    print(f"  Layer {layer_idx}: already active")
                    continue

                layer_prefix = f"model.layers.{layer_idx}."
                layer_weights = {
                    k.replace(layer_prefix, ""): v
                    for k, v in state_dict.items()
                    if k.startswith(layer_prefix)
                }

                if not layer_weights:
                    print(f"  âš ï¸ No weights for layer {layer_idx}")
                    continue

                loaded = self._load_layer_weights(
                    layer_wrapper.layer, layer_weights, weight_pattern, device
                )
                print(f"  âœ… Layer {layer_idx}: {loaded} tensors â†’ GPU")

                layer_wrapper.activate()
                self.initially_inactive.discard(layer_idx)
                print(f"  âœ… Layer {layer_idx} activated (alpha 0â†’1)")

            print(f"\nâœ… Instant activation complete")
            print(f"â„¹ï¸  TopologyëŠ” ê³ ì •ë˜ì§€ë§Œ, vLLM ëŸ°íƒ€ì„ì—ì„œ graph ì¬ìº¡ì²˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ\n")
            return True

        finally:
            # ì„±ê³µ/ì‹¤íŒ¨ ê´€ê³„ì—†ì´ ì „ì²´ prefetch ìƒíƒœ ì •ë¦¬
            self._prefetch_buffer = None
            if hasattr(self, '_prefetch_event'):
                del self._prefetch_event
            if hasattr(self, '_prefetch_path'):
                del self._prefetch_path
            if hasattr(self, '_prefetch_indices'):
                del self._prefetch_indices

    def is_prefetch_ready(self) -> bool:
        """prefetch ì™„ë£Œ ì—¬ë¶€ í™•ì¸ (non-blocking)"""
        return (
            hasattr(self, '_prefetch_event')
            and self._prefetch_event.is_set()
            and self._prefetch_buffer is not None
        )

    def wait_for_prefetch(self, timeout_s: Optional[float] = None) -> bool:
        """
        prefetch ì™„ë£Œê¹Œì§€ ëŒ€ê¸°.

        Returns:
            True: prefetch ì™„ë£Œ + ë²„í¼ ì¤€ë¹„ë¨
            False: ì•„ì§ ë¯¸ì™„ë£Œ/ì‹¤íŒ¨/ë¯¸ì‹œì‘
        """
        if not hasattr(self, '_prefetch_event'):
            return False

        if timeout_s is None:
            finished = self._prefetch_event.wait()
        else:
            finished = self._prefetch_event.wait(timeout=timeout_s)

        if not finished:
            return False
        return self._prefetch_buffer is not None

    def get_prefetch_status(self) -> Dict[str, Any]:
        """prefetch ìƒíƒœ ìŠ¤ëƒ…ìƒ· ë°˜í™˜"""
        has_event = hasattr(self, '_prefetch_event')
        ready = self.is_prefetch_ready()
        in_progress = has_event and (not getattr(self, '_prefetch_event').is_set())

        return {
            "started": has_event,
            "ready": ready,
            "in_progress": in_progress,
            "checkpoint_path": getattr(self, '_prefetch_path', None),
            "layer_indices": list(getattr(self, '_prefetch_indices', [])),
        }

    def _load_layer_weights(
        self,
        layer: nn.Module,
        layer_weights: Dict[str, torch.Tensor],
        weight_pattern: Any,
        device: torch.device,
    ) -> int:
        """
        ë²”ìš© ê°€ì¤‘ì¹˜ ë¡œë”© ë¡œì§
        
        ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜ ì´ë¦„ íŒ¨í„´ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        loaded_count = 0
        
        for name, param in layer.named_parameters():
            # QKV fusion ì²˜ë¦¬
            if weight_pattern.qkv_fused_name and weight_pattern.qkv_fused_name in name:
                qkv_loaded = self._load_qkv_fused(
                    param, name, layer_weights, weight_pattern, device
                )
                if qkv_loaded:
                    loaded_count += 1
                    continue
            
            # MLP Gate-Up fusion ì²˜ë¦¬
            if weight_pattern.mlp_fused_name and weight_pattern.mlp_fused_name in name:
                mlp_loaded = self._load_mlp_fused(
                    param, name, layer_weights, weight_pattern, device
                )
                if mlp_loaded:
                    loaded_count += 1
                    continue
            
            # ì¼ë°˜ weights (direct match)
            if name in layer_weights:
                param.data.copy_(layer_weights[name], non_blocking=True)
                loaded_count += 1
        
        return loaded_count
    
    def _load_qkv_fused(
        self,
        param,
        param_name: str,
        layer_weights: Dict[str, torch.Tensor],
        weight_pattern: Any,
        device: torch.device,
    ) -> bool:
        """QKV fusion weight ë¡œë“œ"""
        # Build expected weight names
        weight_names = []
        for proj_name in weight_pattern.qkv_weights:
            # Extract base path from param_name
            base_path = param_name.replace(f".{weight_pattern.qkv_fused_name}.weight", "")
            weight_name = f"{base_path}.{proj_name}.weight"
            weight_name = weight_name.lstrip('.')  # Remove leading dot
            weight_names.append(weight_name)
        
        # Check if all weights exist
        if all(name in layer_weights for name in weight_names):
            offset = 0
            for name in weight_names:
                t = layer_weights[name]
                n = t.shape[0]
                param.data[offset : offset + n].copy_(t, non_blocking=True)
                offset += n
            print(f"  âœ… Loaded fused QKV ({len(weight_names)} weights â†’ {offset} rows)")
            return True
        
        return False
    
    def _load_mlp_fused(
        self,
        param,
        param_name: str,
        layer_weights: Dict[str, torch.Tensor],
        weight_pattern: Any,
        device: torch.device,
    ) -> bool:
        """MLP Gate-Up fusion weight ë¡œë“œ"""
        if not weight_pattern.mlp_gate_up:
            return False
        
        # Build expected weight names
        weight_names = []
        for proj_name in weight_pattern.mlp_gate_up:
            base_path = param_name.replace(f".{weight_pattern.mlp_fused_name}.weight", "")
            weight_name = f"{base_path}.{proj_name}.weight"
            weight_name = weight_name.lstrip('.')
            weight_names.append(weight_name)
        
        # Check if all weights exist
        if all(name in layer_weights for name in weight_names):
            offset = 0
            for name in weight_names:
                t = layer_weights[name]
                n = t.shape[0]
                param.data[offset : offset + n].copy_(t, non_blocking=True)
                offset += n
            print(f"  âœ… Loaded fused MLP ({len(weight_names)} weights â†’ {offset} rows)")
            return True
        
        return False
    
    # ================================================================
    # Status Methods (CUDA Graph safe!)
    # ================================================================
    
    def get_layer_status(self) -> Dict[int, Dict]:
        """ë ˆì´ì–´ ìƒíƒœ í™•ì¸"""
        status = {}
        for i, layer in enumerate(self.layers):
            alpha_value = layer.get_alpha_value()
            
            status[i] = {
                "type": "DualPath",
                "active": layer.is_active(),
                "alpha": alpha_value,
                "path": "A" if alpha_value > 0.5 else "B"
            }
        return status
    
    def count_inactive_layers(self) -> int:
        """ë¹„í™œì„± ë ˆì´ì–´ ê°œìˆ˜"""
        count = 0
        for layer in self.layers:
            if not layer.is_active():
                count += 1
        return count
    
    def print_layer_status(self) -> None:
        """ë ˆì´ì–´ ìƒíƒœ ì¶œë ¥"""
        status = self.get_layer_status()
        
        print("\n" + "="*60)
        print(f"LAYER STATUS (Dual-Path, {self.model_type.upper()})")
        print("="*60)
        
        for i in range(0, len(status), 10):
            print(f"\nLayers {i:2d}-{min(i+9, len(status)-1):2d}:")
            for j in range(i, min(i+10, len(status))):
                info = status[j]
                alpha = info['alpha']
                path = info['path']
                symbol = "â—‰" if alpha > 0.5 else "âŠ—"
                print(f"  L{j:2d}: {symbol} alpha={alpha:.1f} (Path {path})")
        
        print(f"\nTotal layers: {len(status)}")
        print(f"Path A (active):   {len(status) - self.count_inactive_layers()}")
        print(f"Path B (bypass):   {self.count_inactive_layers()}")
        print("="*60 + "\n")
    
    # ================================================================
    # Additional Status Methods
    # ================================================================
    
    def verify_recovery(self) -> Dict[str, Any]:
        """Progressive recovery ìƒíƒœ í™•ì¸"""
        active = []
        inactive = []
        
        for i, layer in enumerate(self.layers):
            if layer.is_active():
                active.append(i)
            else:
                inactive.append(i)
        
        return {
            "active_layers": active,
            "inactive_layers": inactive,
            "inactive_layer_indices": inactive,
            "activation_progress": f"{len(active)}/{len(self.layers)}",
            "model_type": self.model_type,
        }
    
    def get_adapter_info(self) -> Dict[str, Any]:
        """Adapter ì •ë³´"""
        return {
            "current_adapter": self.current_adapter,
            "adapter_enabled": self.current_adapter is not None
        }
